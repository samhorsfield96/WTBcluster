import glob
import os

configfile: "config_update.yaml"

def get_tokenized_genomes(wildcards):
    checkpoint_output = checkpoints.list_pyrodigal_full.get(**wildcards).output[0]
    return expand("{out_dir}/tokenised_genomes/tokenized_genomes_batch_{batch_ID}.txt", out_dir=config['output_dir'], batch_ID=range(config['mmseqs2_num_batches']))
    
# Define the final output
rule all:
   input:
        f"{config['output_dir']}/merged_clusters/all_clusters.pkl",
        f"{config['output_dir']}/merged_clusters/all_clusters.tsv",
        f"{config['output_dir']}/merged_clusters/reps.pkl",
        get_tokenized_genomes

checkpoint split_file_batch:
    input:
        file_list=f"{config['file_list']}",
    output:
        batches_dir=directory(f"{config['output_dir']}/pyrodigal_input_batches")
    params:
        pyrodigal_num_batches=int(f"{config['pyrodigal_num_batches']}"),
        outpref="pyrodigal_batch_N"
    script: "scripts/split_file_pyrodigal.py"

rule pyrodigal:
    input:
        batch_file=f"{config['output_dir']}/pyrodigal_input_batches/pyrodigal_batch_N{{batch_ID}}.txt"
    output:
        outdir=directory(f"{config['output_dir']}/pyrodigal_annotations/batch_{{batch_ID}}_ann"),
    conda:
        "WTBcluster"
    threads: 1
    script: "scripts/run_pyrodigal.py"

def get_pyrodigal_outputs(wildcards):
    checkpoint_output = checkpoints.split_file_batch.get(**wildcards).output[0]
    return expand("{out_dir}/pyrodigal_annotations/batch_{batch_ID}_ann", out_dir=config['output_dir'], batch_ID=range(config['pyrodigal_num_batches']))

checkpoint list_pyrodigal_full:
    input:
        dir_list=get_pyrodigal_outputs,
    output:
        output_dir=directory(f"{config['output_dir']}/pyrodigal_output_batches"),
    params:
        mmseqs2_num_batches=f"{config['mmseqs2_num_batches']}",
        outpref="mmseqs2_batch_N"
    script: "scripts/split_file_mmseqs.py"

rule concatenate_faa:
    input:
        batch_files=f"{config['output_dir']}/pyrodigal_output_batches",
        prev_run_reps=f"{config['prev_run_reps']}",
    output:
        outfile = f"{config['output_dir']}/mmseqs2_batches/mmseqs2_concat.faa"
    conda:
        "WTBcluster"
    threads: 1
    shell:
        """
        > {output.outfile}
        for file in {input.batch_files}/*; do
            while IFS= read -r line || [[ -n "$line" ]]; do

                cat $line >> {output.outfile}

            done < "${file}"
        done

        cat {input.prev_run_reps} >> {output.outfile}
        """

def get_concatentated_files(wildcards):
   checkpoint_output = checkpoints.list_pyrodigal_full.get(**wildcards).output[0]
   return expand("{out_dir}/mmseqs2_batches/mmseqs2_concat_batch_N{batch_ID}.faa", out_dir=config['output_dir'], batch_ID=range(config['mmseqs2_num_batches']))

# Run MMseqs clustering
checkpoint mmseqs_cluster:
    input:
        input_file=f"{config['output_dir']}/mmseqs2_batches/mmseqs2_concat.faa"
    output:
        output_dir=directory(f"{config['output_dir']}/mmseqs2_clustering")
    threads: 40
    params:
        mmseqs2_tmp_dir=f"{config['mmseqs2_tmp_dir']}",
        mmseqs2_min_ID=f"{config['mmseqs2_min_ID']}",
        mmseqs2_min_cov=f"{config['mmseqs2_min_cov']}",
        mmseqs2_cov_mode=f"{config['mmseqs2_cov_mode']}",
        mmseqs2_cluster_mode=f"{config['mmseqs2_cluster_mode']}",
        mmseqs2_ID_mode=f"{config['mmseqs2_ID_mode']}",
        mmseqs2_alignment_mode=f"{config['mmseqs2_alignment_mode']}",
        outpref="clustering_",
        
    shell: 
        """
        mmseqs easy-linclust {input.input_file} {output.output_dir}/{params.outpref}_final {params.mmseqs2_tmp_dir} \
        --min-seq-id {params.mmseqs2_min_ID} -c {params.mmseqs2_min_cov} --seq-id-mode {params.mmseqs2_ID_mode} \
        --cov-mode {params.mmseqs2_cov_mode} --cluster-mode {params.mmseqs2_cluster_mode} --alignment-mode {params.mmseqs2_alignment_mode} \
        --threads {threads} -v 2
        """

def get_mmseqs2_clusters(wildcards):
    checkpoint_output = checkpoints.mmseqs_cluster.get(**wildcards).output[0]
    return expand("{out_dir}/mmseqs2_clustering/clustering_{batch_ID}_cluster.tsv", out_dir=config['output_dir'], batch_ID=range(config['mmseqs2_num_batches']))

# need to update python function to enable merging of existing clusters, adding to existing 
# corpus but not merging existing cluster.
rule mmseqs_cluster_merge:
    input:
        infiles=get_mmseqs2_clusters
        prev_clusters=f"{config['prev_merged_clusters']}/all_clusters.pkl"
    output:
        clusters = f"{config['output_dir']}/merged_clusters/all_clusters.pkl"
    conda:
        "WTBcluster"
    threads: 1
    script: "scripts/merge_mmseqs2_clusters_update.py"

rule mmseqs_cluster_write:
    input:
        infiles=get_mmseqs2_clusters,
        clusters = f"{config['output_dir']}/merged_clusters/all_clusters.pkl"
    output:
        outfile = f"{config['output_dir']}/merged_clusters/all_clusters.tsv"
    conda:
        "WTBcluster"
    threads: 1
    script: "scripts/write_mmseqs2_clusters.py"

rule update_token_db:
    input:
        clusters = f"{config['output_dir']}/merged_clusters/all_clusters.tsv"
        out_db = f"{config['prev_merged_clusters']}/merged_clusters/gene_tokens.db",
        in_reps = f"{config['prev_merged_clusters']}/merged_clusters/gene_tokens.db",
    output:
        out_reps = f"{config['output_dir']}/merged_clusters/reps.pkl"
    conda:
        "WTBcluster"
    threads: 1
    script: "scripts/update_token_db.py"

rule tokenise_genomes:
    input:
        batch_file=f"{config['output_dir']}/pyrodigal_output_batches/mmseqs2_batch_N{{batch_ID}}_gff.txt",
        out_db = f"{config['prev_merged_clusters']}/merged_clusters/gene_tokens.db",
        out_reps = f"{config['output_dir']}/merged_clusters/reps.pkl"
    output:
        outfile=f"{config['output_dir']}/tokenised_genomes/tokenized_genomes_batch_{{batch_ID}}.txt"
    conda:
        "WTBcluster"
    threads: 1
    script: "scripts/tokenize_genomes.py"